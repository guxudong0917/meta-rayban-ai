/*
 * Omni Realtime ViewModel
 * Manages real-time multimodal conversation with AI
 */

import Foundation
import SwiftUI
import AVFoundation

@MainActor
class OmniRealtimeViewModel: ObservableObject {

    // Published state
    @Published var isConnected = false
    @Published var isRecording = false
    @Published var isSpeaking = false
    @Published var currentTranscript = ""
    @Published var conversationHistory: [ConversationMessage] = []
    @Published var errorMessage: String?
    @Published var showError = false

    // Service
    private var omniService: OmniRealtimeService
    private let apiKey: String

    // Video frame
    private var currentVideoFrame: UIImage?
    private var isImageSendingEnabled = false // æ˜¯å¦å·²å¯ç”¨å›¾ç‰‡å‘é€ï¼ˆç¬¬ä¸€æ¬¡éŸ³é¢‘åï¼‰

    init(apiKey: String) {
        self.apiKey = apiKey
        self.omniService = OmniRealtimeService(apiKey: apiKey)
        setupCallbacks()
    }

    // MARK: - Setup

    private func setupCallbacks() {
        omniService.onConnected = { [weak self] in
            Task { @MainActor in
                self?.isConnected = true
            }
        }

        omniService.onFirstAudioSent = { [weak self] in
            Task { @MainActor in
                print("âœ… [OmniVM] æ”¶åˆ°ç¬¬ä¸€æ¬¡éŸ³é¢‘å‘é€å›è°ƒï¼Œå¯ç”¨å›¾ç‰‡å‘é€")
                // å»¶è¿Ÿ1ç§’åå¯ç”¨å›¾ç‰‡å‘é€èƒ½åŠ›ï¼ˆç¡®ä¿éŸ³é¢‘å·²åˆ°è¾¾ï¼‰
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    self?.isImageSendingEnabled = true
                    print("ğŸ“¸ [OmniVM] å›¾ç‰‡å‘é€å·²å¯ç”¨ï¼Œç­‰å¾…ç”¨æˆ·è¯­éŸ³è§¦å‘")
                }
            }
        }

        omniService.onSpeechStarted = { [weak self] in
            Task { @MainActor in
                self?.isSpeaking = true

                // ç”¨æˆ·è¯­éŸ³è§¦å‘æ¨¡å¼ï¼šæ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯æ—¶ï¼Œå‘é€ä¸€å¸§å›¾ç‰‡
                if let strongSelf = self,
                   strongSelf.isImageSendingEnabled,
                   let frame = strongSelf.currentVideoFrame {
                    print("ğŸ¤ğŸ“¸ [OmniVM] æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³ï¼Œå‘é€å½“å‰è§†é¢‘å¸§")
                    strongSelf.omniService.sendImageAppend(frame)
                }
            }
        }

        omniService.onSpeechStopped = { [weak self] in
            Task { @MainActor in
                self?.isSpeaking = false
            }
        }

        omniService.onTranscriptDelta = { [weak self] delta in
            Task { @MainActor in
                print("ğŸ“ [OmniVM] AIå›å¤ç‰‡æ®µ: \(delta)")
                self?.currentTranscript += delta
            }
        }

        omniService.onUserTranscript = { [weak self] userText in
            Task { @MainActor in
                guard let self = self else { return }
                print("ğŸ’¬ [OmniVM] ä¿å­˜ç”¨æˆ·è¯­éŸ³: \(userText)")
                self.conversationHistory.append(
                    ConversationMessage(role: .user, content: userText)
                )
            }
        }

        omniService.onTranscriptDone = { [weak self] fullText in
            Task { @MainActor in
                guard let self = self else { return }
                // ä½¿ç”¨ç´¯ç§¯çš„currentTranscriptï¼Œå› ä¸ºdoneäº‹ä»¶å¯èƒ½ä¸åŒ…å«textå­—æ®µ
                let textToSave = fullText.isEmpty ? self.currentTranscript : fullText
                guard !textToSave.isEmpty else {
                    print("âš ï¸ [OmniVM] AIå›å¤ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
                    return
                }
                print("ğŸ’¬ [OmniVM] ä¿å­˜AIå›å¤: \(textToSave)")
                self.conversationHistory.append(
                    ConversationMessage(role: .assistant, content: textToSave)
                )
                self.currentTranscript = ""
            }
        }

        omniService.onAudioDone = { [weak self] in
            Task { @MainActor in
                // Audio playback complete
            }
        }

        omniService.onError = { [weak self] error in
            Task { @MainActor in
                self?.errorMessage = error
                self?.showError = true
            }
        }
    }

    // MARK: - Connection

    func connect() {
        omniService.connect()
    }

    func disconnect() {
        // Save conversation before disconnecting
        saveConversation()

        stopRecording()
        omniService.disconnect()
        isConnected = false
        isImageSendingEnabled = false
    }

    private func saveConversation() {
        // Only save if there's meaningful conversation
        guard !conversationHistory.isEmpty else {
            print("ğŸ’¬ [OmniVM] æ— å¯¹è¯å†…å®¹ï¼Œè·³è¿‡ä¿å­˜")
            return
        }

        let record = ConversationRecord(
            messages: conversationHistory,
            aiModel: "qwen3-omni-flash-realtime",
            language: "zh-CN" // TODO: ä»è®¾ç½®ä¸­è·å–
        )

        ConversationStorage.shared.saveConversation(record)
        print("ğŸ’¾ [OmniVM] å¯¹è¯å·²ä¿å­˜: \(conversationHistory.count) æ¡æ¶ˆæ¯")
    }

    // MARK: - Recording

    func startRecording() {
        guard isConnected else {
            print("âš ï¸ [OmniVM] æœªè¿æ¥ï¼Œæ— æ³•å¼€å§‹å½•éŸ³")
            errorMessage = "è¯·å…ˆè¿æ¥æœåŠ¡å™¨"
            showError = true
            return
        }

        print("ğŸ¤ [OmniVM] å¼€å§‹å½•éŸ³ï¼ˆè¯­éŸ³è§¦å‘æ¨¡å¼ï¼‰")
        omniService.startRecording()
        isRecording = true
    }

    func stopRecording() {
        print("ğŸ›‘ [OmniVM] åœæ­¢å½•éŸ³")
        omniService.stopRecording()
        isRecording = false
    }

    // MARK: - Video Frames

    func updateVideoFrame(_ frame: UIImage) {
        currentVideoFrame = frame
    }

    // MARK: - Manual Mode (if needed)

    func sendMessage() {
        omniService.commitAudioBuffer()
    }

    // MARK: - Cleanup

    func dismissError() {
        showError = false
    }

    nonisolated deinit {
        Task { @MainActor [weak omniService] in
            omniService?.disconnect()
        }
    }
}

// MARK: - Conversation Message

struct ConversationMessage: Identifiable {
    let id = UUID()
    let role: MessageRole
    let content: String
    let timestamp = Date()

    enum MessageRole {
        case user
        case assistant
    }
}
